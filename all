"""
Extract ALL data from a partitioned table - partition by partition
- Extracts each partition to a separate CSV
- Parallel extraction for speed
- Progress tracking
"""

import os
import sys
import csv
import gc
import oracledb
from datetime import datetime
from multiprocessing import Pool

# Database connection details
SCHEMA = "placeholder"
DB_USER = SCHEMA
DB_PASSWORD = "placeholder"
DB_HOST = "placeholder"
DB_PORT = "placeholder"
DB_SID = "placeholder"

# Performance settings
FETCH_SIZE = 500000       # Rows to fetch at once
PARALLEL_EXTRACTS = 16    # Parallel partition extractions
WRITE_BUFFER = 64*1024*1024  # 64MB write buffer
OUTPUT_DIR = "."          # Output directory

# Oracle Instant Client
ORACLE_CLIENT_PATH = r"D:\Homeware\instantclient_23_0"

def init_oracle_client():
    try:
        oracledb.init_oracle_client(lib_dir=ORACLE_CLIENT_PATH)
    except oracledb.ProgrammingError:
        pass
    except Exception as e:
        print(f"ERROR: {e}")
        sys.exit(1)

def worker_init():
    """Initialize each worker process"""
    init_oracle_client()

def get_connection():
    dsn = oracledb.makedsn(DB_HOST, DB_PORT, sid=DB_SID)
    conn = oracledb.connect(f"{DB_USER}/{DB_PASSWORD}@{dsn}")
    return conn

def get_partitions(table_name):
    """Get all partitions for a table"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT partition_name, num_rows
        FROM all_tab_partitions
        WHERE table_owner = :1 AND table_name = :2
        ORDER BY partition_position
    """, [SCHEMA.upper(), table_name.upper()])
    
    partitions = cursor.fetchall()
    cursor.close()
    conn.close()
    return partitions

def get_columns(table_name):
    """Get column names for a table"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT column_name FROM all_tab_columns
        WHERE owner = :1 AND table_name = :2
        ORDER BY column_id
    """, [SCHEMA.upper(), table_name.upper()])
    
    columns = [row[0] for row in cursor.fetchall()]
    cursor.close()
    conn.close()
    return columns

def extract_partition(args):
    """Extract a single partition to CSV"""
    table_name, partition_name, partition_idx, total, columns, output_dir = args
    
    gc.collect()
    
    output_file = os.path.join(output_dir, f"{table_name}_{partition_idx:04d}.csv")
    
    try:
        conn = get_connection()
        cursor = conn.cursor()
        cursor.arraysize = FETCH_SIZE
        cursor.prefetchrows = FETCH_SIZE
        
        # Query partition
        col_list = ", ".join(columns)
        sql = f"SELECT {col_list} FROM {SCHEMA}.{table_name} PARTITION ({partition_name})"
        cursor.execute(sql)
        
        rows_written = 0
        
        with open(output_file, 'w', newline='', encoding='utf-8', buffering=WRITE_BUFFER) as f:
            writer = csv.writer(f)
            writer.writerow(columns)  # Header
            
            while True:
                rows = cursor.fetchmany(FETCH_SIZE)
                if not rows:
                    break
                writer.writerows(rows)
                rows_written += len(rows)
        
        cursor.close()
        conn.close()
        gc.collect()
        
        size_mb = os.path.getsize(output_file) / (1024 * 1024)
        print(f"  [{partition_idx:04d}/{total}] {partition_name}: {rows_written:,} rows ({size_mb:.1f} MB)")
        
        return partition_idx, True, rows_written, output_file
        
    except Exception as e:
        print(f"  [{partition_idx:04d}/{total}] {partition_name}: ERROR - {e}")
        return partition_idx, False, 0, None

def main():
    print("="*70)
    print("EXTRACT ALL PARTITIONS")
    print("="*70)
    
    init_oracle_client()
    print("Oracle thick mode initialized")
    
    # Get table name
    table_name = input("\nEnter table name: ").strip().upper()
    if not table_name:
        print("ERROR: Table name required!")
        return
    
    # Get partitions
    print(f"\nFetching partitions for {SCHEMA}.{table_name}...")
    partitions = get_partitions(table_name)
    
    if not partitions:
        print("No partitions found! Is this a partitioned table?")
        return
    
    # Get columns
    columns = get_columns(table_name)
    if not columns:
        print("ERROR: Could not get column list!")
        return
    
    # Calculate total rows
    total_rows = sum(p[1] or 0 for p in partitions)
    
    print(f"\nTable: {SCHEMA}.{table_name}")
    print(f"Partitions: {len(partitions)}")
    print(f"Columns: {len(columns)}")
    print(f"Estimated rows: {total_rows:,}")
    
    # Output directory
    output_dir = input(f"\nOutput directory (default: {OUTPUT_DIR}): ").strip() or OUTPUT_DIR
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created directory: {output_dir}")
    
    # Optional: extract range
    print(f"\nExtract range (1 to {len(partitions)}):")
    start = input(f"  Start partition (default: 1): ").strip()
    start = int(start) if start.isdigit() else 1
    end = input(f"  End partition (default: {len(partitions)}): ").strip()
    end = int(end) if end.isdigit() else len(partitions)
    
    # Validate range
    start = max(1, min(start, len(partitions)))
    end = max(start, min(end, len(partitions)))
    
    selected = partitions[start-1:end]
    selected_rows = sum(p[1] or 0 for p in selected)
    
    print(f"\nWill extract {len(selected)} partitions ({start} to {end})")
    print(f"Estimated rows: {selected_rows:,}")
    
    confirm = input("\nContinue? (y/n): ").strip().lower()
    if confirm != 'y':
        print("Cancelled.")
        return
    
    # Prepare args
    args_list = [
        (table_name, part[0], start + i, len(selected), columns, output_dir)
        for i, part in enumerate(selected)
    ]
    
    print("\n" + "="*70)
    print(f"EXTRACTING {len(selected)} PARTITIONS (PARALLEL {PARALLEL_EXTRACTS})")
    print("="*70 + "\n")
    
    start_time = datetime.now()
    
    # Extract in parallel
    with Pool(processes=PARALLEL_EXTRACTS, initializer=worker_init) as pool:
        results = pool.map(extract_partition, args_list)
    
    elapsed = (datetime.now() - start_time).total_seconds()
    
    # Summary
    print("\n" + "="*70)
    print("EXTRACTION COMPLETE")
    print("="*70)
    
    success = sum(1 for r in results if r[1])
    total_rows = sum(r[2] for r in results)
    
    print(f"Partitions: {success}/{len(selected)}")
    print(f"Total rows: {total_rows:,}")
    print(f"Time: {elapsed:.1f}s ({elapsed/60:.1f} minutes)")
    print(f"Speed: {total_rows/elapsed:,.0f} rows/sec")
    print(f"Output: {output_dir}")

if __name__ == "__main__":
    main()
